import json
import os
import re
import time
from typing import Optional, Dict, Any
from urllib.parse import unquote

import requests
import undetected_chromedriver as uc
from selenium.common.exceptions import TimeoutException, StaleElementReferenceException
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait

SEARCH_NUMBER = "25386"
SEARCH_TYPE = "HRB"
SEARCH_TOWN = "alle"
OUTPUT_JSON = "result.json"
SESSION_COOKIES_FILE = "session_cookies.json"

_captured_requests = []

def build_driver() -> uc.Chrome:
    """Konfiguracja sterownika Chrome - TYLKO do przechwytywania request√≥w, NIE pobiera plik√≥w."""
    options = uc.ChromeOptions()
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--window-size=1280,720")
    #options.add_argument("--headless")  # Odkomentuj dla trybu bezokienkowego

    driver = uc.Chrome(options=options)

    options.set_capability("goog:loggingPrefs", {"performance": "ALL"})

    try:
        driver.execute_cdp_cmd("Network.enable", {})
    except Exception:
        pass

    return driver

def wait_for_loading_gone(driver, timeout=10):
    try:
        WebDriverWait(driver, timeout).until(
            EC.invisibility_of_element_located((By.CLASS_NAME, "ui-icon-loading"))
        )
        # Czasami jest te≈º blokada ca≈Çego ekranu
        WebDriverWait(driver, timeout).until(
            EC.invisibility_of_element_located((By.ID, "j_idt15:statusDialog"))
        )
    except Exception:
        pass  # Je≈õli nie znaleziono loadera, to znaczy ≈ºe go nie ma, idziemy dalej


def save_session_cookies(driver, cookies_file: str = SESSION_COOKIES_FILE):
    """Zapisuje cookies z aktywnej sesji Selenium do pliku JSON."""
    try:
        cookies = driver.get_cookies()
        os.makedirs(os.path.dirname(cookies_file) or ".", exist_ok=True)
        with open(cookies_file, "w", encoding="utf-8") as f:
            json.dump(cookies, f, indent=2, ensure_ascii=False)
        print(f"‚úÖ Zapisano {len(cookies)} cookies do {cookies_file}")
        return True
    except Exception as e:
        print(f"‚ö†Ô∏è B≈ÇƒÖd przy zapisywaniu cookies: {e}")
        return False


def load_session_cookies(cookies_file: str = SESSION_COOKIES_FILE):
    """≈Åaduje cookies z pliku JSON."""
    try:
        if not os.path.exists(cookies_file):
            return []
        with open(cookies_file, "r", encoding="utf-8") as f:
            cookies = json.load(f)
        return cookies if isinstance(cookies, list) else []
    except Exception as e:
        print(f"‚ö†Ô∏è B≈ÇƒÖd przy ≈Çadowaniu cookies: {e}")
        return []


def download_file_with_post(
    post_url: str,
    post_params: dict,
    output_path: str = None,
    cookies_file: str = SESSION_COOKIES_FILE
) -> tuple[bool, Optional[str]]:
    """
    Pobiera plik u≈ºywajƒÖc POST request z zapisanymi cookies z sesji Selenium.
    
    Args:
        post_url: URL do POST requestu (np. 'https://www.handelsregister.de/rp_web/sucheErgebnisse/welcome.xhtml?cid=1')
        post_params: S≈Çownik z parametrami POST (jak z przechwyconego requestu)
        output_path: ≈öcie≈ºka do zapisania pliku (opcjonalnie - je≈õli None, u≈ºyje nazwy z Content-Disposition)
        cookies_file: Plik z zapisanymi cookies (domy≈õlnie session_cookies.json)
    
    Returns:
        tuple: (success: bool, filename: str lub None)
    """
    try:
        cookies_list = load_session_cookies(cookies_file)
        if not cookies_list:
            print(f"‚ö†Ô∏è Brak zapisanych cookies w {cookies_file}. Najpierw uruchom scrapowanie.")
            return False, None
        
        # Konwertujemy cookies z formatu Selenium do formatu requests
        cookies_dict = {cookie["name"]: cookie["value"] for cookie in cookies_list}
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Content-Type": "application/x-www-form-urlencoded",
            "Referer": post_url.split("?")[0],  # URL bez parametr√≥w query
            "Origin": "https://www.handelsregister.de",
            "Accept": "*/*",
            "Accept-Language": "de-DE,de;q=0.9,en-US;q=0.8,en;q=0.7",
        }
        
        # Wykonujemy POST request
        response = requests.post(
            post_url,
            data=post_params,
            cookies=cookies_dict,
            headers=headers,
            allow_redirects=True,
            timeout=30
        )
        
        if response.status_code == 200:
            # Pr√≥bujemy wyciƒÖgnƒÖƒá nazwƒô pliku z Content-Disposition
            content_disposition = response.headers.get("Content-Disposition", "")
            filename = None
            
            if content_disposition:
                # Parsujemy: attachment;filename="SN-Chemnitz_HRB_25386+SI-20251210175648.xml"
                filename_match = re.search(r'filename[^;=\n]*=(([\'"]).*?\2|[^;\n]*)', content_disposition)
                if filename_match:
                    filename = filename_match.group(1).strip('"\'')
                    # Dekodujemy URL encoding je≈õli potrzeba
                    try:
                        filename = unquote(filename)
                    except:
                        pass
            
            # Je≈õli nie mamy nazwy z Content-Disposition, u≈ºywamy podanej lub generujemy
            if not filename:
                if output_path:
                    filename = os.path.basename(output_path)
                else:
                    # Generujemy nazwƒô na podstawie timestampu
                    filename = f"download_{int(time.time())}.xml"
            
            # Ustalamy pe≈ÇnƒÖ ≈õcie≈ºkƒô do zapisu
            if output_path:
                final_path = output_path
            else:
                # U≈ºywamy nazwy z Content-Disposition w bie≈ºƒÖcym katalogu
                final_path = filename
            
            # Tworzymy katalog je≈õli potrzeba
            os.makedirs(os.path.dirname(final_path) or ".", exist_ok=True)
            
            # Zapisujemy plik
            with open(final_path, "wb") as f:
                f.write(response.content)
            
            print(f"‚úÖ Pobrano plik: {final_path} ({len(response.content)} bajt√≥w)")
            if content_disposition:
                print(f"   üìÑ Nazwa z Content-Disposition: {content_disposition}")
            return True, final_path
        else:
            print(f"‚ùå B≈ÇƒÖd pobierania: Status {response.status_code}")
            if response.status_code == 440:
                print("‚ö†Ô∏è Sesja wygas≈Ça! Uruchom ponownie scrapowanie, aby od≈õwie≈ºyƒá cookies.")
            return False, None
            
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd przy pobieraniu pliku: {e}")
        return False, None


def inject_request_interceptor(driver):
    """
    Wstrzykuje JavaScript do przechwytywania PrimeFaces.addSubmitParam i XMLHttpRequest.
    Przechwytuje parametry PRZED faktycznym wys≈Çaniem requestu (podobne do Filter po stronie serwera).
    """
    interceptor_script = """
    (function() {
        window._capturedRequests = window._capturedRequests || [];
        
        // Przechwytujemy PrimeFaces.addSubmitParam
        if (window.PrimeFaces && window.PrimeFaces.addSubmitParam) {
            const originalAddSubmitParam = window.PrimeFaces.addSubmitParam;
            window.PrimeFaces.addSubmitParam = function(formId, params) {
                // Zapisujemy parametry przed faktycznym submitem
                const capturedData = {
                    formId: formId,
                    params: params,
                    url: window.location.href.split('#')[0],
                    timestamp: new Date().toISOString()
                };
                window._capturedRequests.push(capturedData);
                
                // Wywo≈Çujemy oryginalnƒÖ funkcjƒô (≈ºeby strona dzia≈Ça≈Ça normalnie)
                return originalAddSubmitParam.apply(this, arguments);
            };
        }
        
        const originalXHROpen = XMLHttpRequest.prototype.open;
        const originalXHRSend = XMLHttpRequest.prototype.send;
        
        XMLHttpRequest.prototype.open = function(method, url, async, user, password) {
            this._interceptedMethod = method;
            this._interceptedUrl = url;
            return originalXHROpen.apply(this, arguments);
        };
        
        XMLHttpRequest.prototype.send = function(data) {
            // Sprawdzamy czy to POST request do handelsregister.de
            if (this._interceptedMethod === 'POST' && 
                this._interceptedUrl && 
                this._interceptedUrl.includes('handelsregister.de')) {
                
                // Parsujemy post data
                let postParams = {};
                if (data) {
                    const params = data.split('&');
                    for (let param of params) {
                        if (param.includes('=')) {
                            const [key, value] = param.split('=');
                            try {
                                postParams[decodeURIComponent(key)] = decodeURIComponent(value);
                            } catch(e) {
                                postParams[key] = value;
                            }
                        }
                    }
                }
                
                // Zapisujemy przechwycony request
                const capturedRequest = {
                    url: this._interceptedUrl,
                    method: this._interceptedMethod,
                    post_data: data || '',
                    post_parameters: postParams,
                    headers: {},
                    timestamp: new Date().toISOString()
                };
                
                window._capturedRequests.push(capturedRequest);
                
                this.abort();
                return;
            }
            
            return originalXHRSend.apply(this, arguments);
        };
        
        if (window.fetch) {
            const originalFetch = window.fetch;
            window.fetch = function(url, options) {
                if (options && options.method === 'POST' && 
                    url && url.includes('handelsregister.de')) {
                    
                    // Sprawdzamy czy to request dla SI
                    const isSIRequest = options.body && options.body.includes('Global.Dokumentart.SI');
                    
                    if (isSIRequest) {
                        let postParams = {};
                        if (options.body) {
                            const params = options.body.split('&');
                            for (let param of params) {
                                if (param.includes('=')) {
                                    const [key, value] = param.split('=');
                                    try {
                                        postParams[decodeURIComponent(key)] = decodeURIComponent(value);
                                    } catch(e) {
                                        postParams[key] = value;
                                    }
                                }
                            }
                        }
                        
                        const capturedRequest = {
                            url: url,
                            method: 'POST',
                            post_data: options.body || '',
                            post_parameters: postParams,
                            headers: options.headers || {},
                            timestamp: new Date().toISOString(),
                            document_type: "SI"
                        };
                        
                        window._capturedRequests.push(capturedRequest);
                        
                        // Anulujemy request
                        return Promise.reject(new Error('Request intercepted and aborted'));
                    }
                }
                
                return originalFetch.apply(this, arguments);
            };
        }
    })();
    """
    
    try:
        driver.execute_script(interceptor_script)
    except Exception as e:
        print(f"‚ö†Ô∏è B≈ÇƒÖd przy wstrzykiwaniu interceptor: {e}")


def get_captured_requests(driver) -> list:
    """Pobiera przechwycone requesty z JavaScript (podobne do UrlHistory.getStore())."""
    try:
        captured = driver.execute_script("return window._capturedRequests || [];")
        return captured if captured else []
    except Exception:
        return []


def extract_params_from_onclick(onclick: str, link_id: str, current_url: str) -> Optional[dict]:
    """
    WyciƒÖga parametry POST z onclick BEZ wykonywania klikniƒôcia.
    NIE KLIKA - tylko parsuje JavaScript z onclick.
    Zwraca dict z URL i parametrami POST.
    """
    try:
        if not onclick or "PrimeFaces" not in onclick or "Global.Dokumentart.SI" not in onclick:
            return None
        
        # WyciƒÖgamy form name z onclick
        form_match = re.search(r"submit\(['\"]([^'\"]+)['\"]\)", onclick)
        form_name = form_match.group(1) if form_match else "ergebnissForm"
        
        # Budujemy s≈Çownik parametr√≥w POST na podstawie onclick
        post_params = {}
        
        # WyciƒÖgamy wszystkie parametry z onclick (wszystkie pary key:value)
        all_params_match = re.findall(r"'([^']+)':\s*'([^']*)'", onclick)
        for key, value in all_params_match:
            # Usuwamy spacje z klucza (czasami jest spacja po dwukropku)
            key = key.strip()
            post_params[key] = value
        
        # Tworzymy dict z parametrami requestu
        return {
            "url": current_url.split("#")[0],
            "method": "POST",
            "post_data": "&".join([f"{k}={v}" for k, v in post_params.items()]),
            "post_parameters": post_params,
            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S"),
            "document_type": "SI",
        }
        
    except Exception as e:
        print(f"‚ö†Ô∏è B≈ÇƒÖd przy wyciƒÖganiu parametr√≥w z onclick: {e}")
        return None


def capture_request_from_onclick(driver, link_element, clear_before: bool = False) -> Optional[dict]:
    """
    Przechwytuje POST request wywo≈Çywany przez onclick PRZED jego faktycznym wys≈Çaniem.
    U≈ºywa wstrzykniƒôtego JavaScript do przechwycenia requestu i anulowania go.
    Zwraca dict z URL i parametrami POST.
    """
    global _captured_requests
    
    try:
        link_id = link_element.get_attribute("id")
        if not link_id:
            return None

        before_count = len(get_captured_requests(driver))

        if clear_before:
            driver.execute_script("window._capturedRequests = [];")
            before_count = 0

        driver.execute_script("arguments[0].click();", link_element)
        
        # Czekamy kr√≥tko na przechwycenie
        time.sleep(2)

        captured_list = get_captured_requests(driver)
        new_requests = captured_list[before_count:]
        
        for req in new_requests:
            if (req.get("method") == "POST" and 
                "handelsregister.de" in req.get("url", "") and 
                link_id in req.get("post_data", "")):

                _captured_requests.append(req)
                return req

        for req in captured_list:
            if (req.get("method") == "POST" and 
                "handelsregister.de" in req.get("url", "") and 
                link_id in req.get("post_data", "")):

                if req not in _captured_requests:
                    _captured_requests.append(req)
                    return req
        
        return None
        
    except Exception as e:
        print(f"‚ö†Ô∏è B≈ÇƒÖd przy przechwytywaniu requestu: {e}")
        return None


def reconstruct_download_url(driver, link_element, onclick: str) -> tuple[Optional[str], Optional[dict], Optional[dict]]:
    """
    WyciƒÖga parametry POST z onclick BEZ wykonywania klikniƒôcia i BEZ pobierania pliku.
    TYLKO parsuje JavaScript z onclick - NIE KLIKA!
    Zwraca tuple: (base_url, post_params_dict, captured_request_dict)
    """
    try:
        current_url = driver.current_url.split("#")[0]
        link_id = link_element.get_attribute("id") or ""
        
        # WyciƒÖgamy parametry z onclick BEZ klikania
        captured_request = extract_params_from_onclick(onclick, link_id, current_url)
        
        if captured_request:
            url = captured_request.get("url")
            post_params = captured_request.get("post_parameters", {})
            return url, post_params, captured_request
        
        return None, None, None
        
    except Exception as e:
        print(f"‚ö†Ô∏è B≈ÇƒÖd przy wyciƒÖganiu parametr√≥w z onclick: {e}")
        return None, None, None


def extract_link_info(link_element, driver=None) -> Dict[str, Any]:
    """
    WyciƒÖga szczeg√≥≈Çowe informacje o linku, w tym rzeczywisty URL dla link√≥w z href="#".
    Dla PrimeFaces link√≥w z onclick, pr√≥buje wyciƒÖgnƒÖƒá parametry z JavaScript.
    Je≈õli podano driver, pr√≥buje przechwyciƒá rzeczywisty URL do pobrania.
    """
    try:
        href = link_element.get_attribute("href") or "#"
        text = link_element.text.strip()
        title = link_element.get_attribute("title") or ""
        onclick = link_element.get_attribute("onclick") or ""
        id_attr = link_element.get_attribute("id") or ""
        
        # Sprawdzamy r√≥≈ºne atrybuty, kt√≥re mogƒÖ zawieraƒá URL
        data_url = link_element.get_attribute("data-url") or link_element.get_attribute("data-href")
        formaction = link_element.get_attribute("formaction")
        
        link_info = {
            "href": href,
            "text": text,
            "title": title,
            "id": id_attr,
            "onclick": onclick[:500] if onclick else "",  # Pierwsze 500 znak√≥w onclick
            "data_url": data_url,
            "formaction": formaction,
        }
        
        # Je≈õli href to "#", pr√≥bujemy wyciƒÖgnƒÖƒá wiƒôcej informacji
        if href == "#" or href.startswith("javascript:") or (href and "#" in href and href.endswith("#")):
            # Dla PrimeFaces - wyciƒÖgamy ID elementu i parametry z onclick
            if id_attr:
                link_info["element_id"] = id_attr
                
            # Pr√≥bujemy wyciƒÖgnƒÖƒá parametry z onclick (dla PrimeFaces)
            if "PrimeFaces" in onclick:
                property_match = re.search(r"'property':\s*'([^']+)'", onclick)
                if property_match:
                    link_info["property"] = property_match.group(1)

                form_match = re.search(r"submit\(['\"]([^'\"]+)['\"]\)", onclick)
                if form_match:
                    link_info["form_name"] = form_match.group(1)

        actual_url = href
        if data_url:
            actual_url = data_url
        elif formaction:
            actual_url = formaction
        elif href != "#" and not href.startswith("javascript:") and not (href.endswith("#") and "#" in href):
            actual_url = href

        if driver and "PrimeFaces" in onclick and "Global.Dokumentart.SI" in onclick:
            try:
                base_url, post_params, captured_request = reconstruct_download_url(driver, link_element, onclick)
                if base_url and post_params:
                    link_info["request_url"] = base_url
                    actual_url = base_url
                    
                    # Szczeg√≥≈Çowe informacje o POST request
                    link_info["request"] = {
                        "method": "POST",
                        "url": base_url,
                        "content_type": "application/x-www-form-urlencoded",
                        "parameters": post_params,
                    }
                    
                    # Je≈õli przechwycili≈õmy rzeczywisty request, dodajemy szczeg√≥≈Çy z pe≈Çnymi danymi
                    if captured_request:
                        link_info["captured_request"] = {
                            "url": captured_request.get("url"),
                            "method": captured_request.get("method"),
                            "post_data": captured_request.get("post_data"),  # Surowy string POST data
                            "post_parameters": captured_request.get("post_parameters"),  # Parsowane parametry
                            "timestamp": captured_request.get("timestamp"),
                            "document_type": captured_request.get("document_type", "SI"),
                        }
                    
                    # Dodatkowo: URL z parametrami jako GET (dla informacji, choƒá faktycznie to POST)
                    get_params = "&".join([f"{k}={v}" for k, v in post_params.items()])
                    link_info["request_url_with_params"] = f"{base_url}?{get_params}"
            except Exception as e:
                print(f"‚ö†Ô∏è B≈ÇƒÖd przy przechwytywaniu requestu dla linku {id_attr}: {e}")
        
        link_info["actual_url"] = actual_url
        
        return link_info
        
    except Exception as e:
        return {
            "href": "#",
            "text": "",
            "title": "",
            "error": str(e),
            "actual_url": "#"
        }


def run_full_flow(target_url: str, download_dir: str = "") -> None:
    driver = None
    try:
        driver = build_driver()
        wait = WebDriverWait(driver, 10)
        driver.get(target_url)

        inject_request_interceptor(driver)

        print("NORMAL SUCHE")
        normale_suche = wait.until(
            EC.element_to_be_clickable((By.ID, "naviForm:normaleSucheLink"))
        )
        normale_suche.click()
        wait_for_loading_gone(driver)

        # 3. Wype≈Çnianie formularza (INPUT DATA)
        print(f"SEARCH PAGE")

        # HRB #
        register_label = wait.until(EC.element_to_be_clickable((By.ID, "form:registerArt_label")))
        register_label.click()
        time.sleep(1)
        hrb_option = wait.until(EC.element_to_be_clickable((By.XPATH, f"//li[contains(text(), '{SEARCH_TYPE}')]")))
        hrb_option.click()
        wait_for_loading_gone(driver)
        time.sleep(1)

        # NUMBER
        register_input = wait.until(EC.presence_of_element_located((By.ID, "form:registerNummer")))
        register_input.clear()
        register_input.send_keys(SEARCH_NUMBER)

        # ALL #
        register_label1 = wait.until(EC.element_to_be_clickable((By.ID, "form:registergericht_label")))
        register_label1.click()
        time.sleep(2)
        town_option = wait.until(EC.element_to_be_clickable((By.XPATH, f"//ul[@id='form:registergericht_items']//li[@data-label='{SEARCH_TOWN}']")))
        town_option.click()
        wait_for_loading_gone(driver)
        time.sleep(1)

        # Opcjonalnie: Ustawienie 100 wynik√≥w
        try:
            per_page_label = driver.find_element(By.ID, "form:ergebnisseProSeite_label")
            per_page_label.click()
            per_page_100 = wait.until(EC.element_to_be_clickable((By.XPATH, "//li[contains(@data-label, '100')]")))
            per_page_100.click()
            wait_for_loading_gone(driver)
        except Exception:
            print("‚ö†Ô∏è Nie uda≈Ço siƒô zmieniƒá liczby wynik√≥w na 100, zostawiam domy≈õlnƒÖ.")

        # 4. Klikniƒôcie SZUKAJ
        suche_btn = driver.find_element(By.ID, "form:btnSuche")
        driver.execute_script("arguments[0].click();", suche_btn)

        wait.until(EC.presence_of_element_located((By.ID, "ergebnissForm:selectedSuchErgebnisFormTable_data")))
        wait_for_loading_gone(driver)

        # Zapisujemy cookies z aktywnej sesji (potrzebne do p√≥≈∫niejszego pobierania plik√≥w)
        save_session_cookies(driver)

        rows = driver.find_elements(By.XPATH, "//tbody[@id='ergebnissForm:selectedSuchErgebnisFormTable_data']/tr")

        collected_links = []

        for row_index, row in enumerate(rows):
            try:
                si_links = row.find_elements(
                    By.XPATH, 
                    f".//a[contains(@onclick, 'Global.Dokumentart.SI')]"
                )
                
                row_data = {
                    "row_number": row_index,
                    "row_display": row_index + 1,
                    "si_links": []
                }

                for link in si_links:
                    try:
                        onclick = link.get_attribute("onclick") or ""
                        if "Global.Dokumentart.SI" not in onclick:
                            continue

                        # Sprawdzamy czy ID ma poprawny format z numerem wiersza
                        link_id = link.get_attribute("id") or ""
                        expected_id_pattern = f"ergebnissForm:selectedSuchErgebnisFormTable:{row_index}:"
                        if expected_id_pattern not in link_id:
                            print(f"‚ö†Ô∏è Wiersz {row_index}: Nieoczekiwany format ID: {link_id}")
                            continue
                        
                        # Przechwytujemy request
                        link_info = extract_link_info(link, driver)

                        if link_info.get("request") or link_info.get("captured_request"):
                            if not link_info.get("request") and link_info.get("captured_request"):
                                captured = link_info.get("captured_request")
                                link_info["request"] = {
                                    "method": captured.get("method", "POST"),
                                    "url": captured.get("url"),
                                    "content_type": "application/x-www-form-urlencoded",
                                    "parameters": captured.get("post_parameters", {}),
                                }
                            
                            row_data["si_links"].append(link_info)
                        else:
                            print(f"‚ö†Ô∏è Wiersz {row_index}: Nie uda≈Ço siƒô przechwyciƒá requestu dla linku SI")
                            
                    except Exception as e:
                        print(f"‚ö†Ô∏è B≈ÇƒÖd przy zbieraniu linku SI w wierszu {row_index}: {e}")
                        continue

                if row_data["si_links"]:
                    collected_links.append(row_data)

            except StaleElementReferenceException:
                print(f"‚ö†Ô∏è Rekord {row_index}: Element wygas≈Ç (DOM od≈õwie≈ºony).")
                continue
            except Exception as e:
                print(f"‚ùå B≈ÇƒÖd przy rekordzie {row_index}: {e}")

        # Zapisujemy zebrane requesty z parametrami do JSON
        wynik = {
            "count": len(collected_links),
            "items": collected_links,
        }
        time.sleep(1)

        os.makedirs(os.path.dirname(OUTPUT_JSON) or ".", exist_ok=True)
        with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
            json.dump(wynik, f, indent=4, ensure_ascii=False)

        total_si_requests = sum(len(item.get("si_links", [])) for item in collected_links)
        print(f"≈ÅƒÖcznie przechwycono {total_si_requests} request√≥w SI z parametrami POST")

    except Exception as e:
        print(f"‚ùå KRYTYCZNY B≈ÅƒÑD SKRYPTU: {e}")
        # Zrzut ekranu do debugowania
        if driver:
            driver.save_screenshot("error_debug.png")
    finally:
        if driver:
            driver.quit()


if __name__ == "__main__":
    target_url = "https://www.handelsregister.de/"

    run_full_flow(target_url, download_dir="")
    
    # PRZYK≈ÅAD: Jak pobraƒá plik u≈ºywajƒÖc przechwyconych parametr√≥w POST
    # 
    # 1. Po uruchomieniu run_full_flow(), masz:
    #    - result.json z przechwyconymi parametrami POST
    #    - session_cookies.json z cookies sesji
    #
    # 2. Mo≈ºesz u≈ºyƒá funkcji download_file_with_post():
    #
    #    from SeleniumScraper import download_file_with_post
    #
    #    post_url = "https://www.handelsregister.de/rp_web/sucheErgebnisse/welcome.xhtml?cid=1"
    #    post_params = {
    #        "ergebnissForm:selectedSuchErgebnisFormTable:0:j_idt219:6:fade_": "ergebnissForm:selectedSuchErgebnisFormTable:0:j_idt219:6:fade_",
    #        "property": "Global.Dokumentart.SI"
    #    }
    #    
    #    success, filename = download_file_with_post(
    #        post_url=post_url,
    #        post_params=post_params,
    #        output_path="pobrany_plik.xml"  # opcjonalnie - je≈õli None, u≈ºyje nazwy z Content-Disposition
    #    )
    #
    # 3. Lub u≈ºyj skryptu pomocniczego:
    #
    #    python download_files.py
    #
    #    Ten skrypt automatycznie pobierze wszystkie pliki z result.json u≈ºywajƒÖc
    #    przechwyconych parametr√≥w POST i zapisanych cookies.