import time
import os
import json
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait
from selenium.common.exceptions import StaleElementReferenceException

# --- KONFIGURACJA ---
TARGET_URL = "https://www2.hm.com/pl_pl/on/produkty/view-all.html"
OUTPUT_FILE = "hm_links_with_session.txt"


def build_driver():
    options = uc.ChromeOptions()
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--window-size=1280,800")
    return uc.Chrome(options=options)


def handle_cookies(driver, wait):
    """H&M wymaga akceptacji cookies, inaczej zas≈ÇaniajƒÖ ekran."""
    print("üç™ Szukam banera cookies...")
    try:
        accept_btn = wait.until(EC.element_to_be_clickable((By.ID, "onetrust-accept-btn-handler")))
        accept_btn.click()
        print("‚úÖ Zaakceptowano cookies.")
        time.sleep(1)
    except Exception:
        print("‚ö†Ô∏è Nie znaleziono banera cookies (mo≈ºe ju≈º zaakceptowane).")


def scroll_page(driver):
    """H&M wymaga przewijania, aby za≈Çadowaƒá produkty (Lazy Loading)."""
    print("üìú Przewijanie strony...")
    for _ in range(3):  # Przewi≈Ñ 3 razy
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(1.5)
    driver.execute_script("window.scrollTo(0, 0);")  # Wr√≥ƒá na g√≥rƒô
    time.sleep(1)


def run_scraper():
    driver = None
    try:
        print("üöÄ Uruchamianie przeglƒÖdarki...")
        driver = build_driver()
        wait = WebDriverWait(driver, 15)

        print(f"üåê Wchodzenie na: {TARGET_URL}")
        driver.get(TARGET_URL)

        # Obs≈Çuga specyficzna dla H&M
        handle_cookies(driver, wait)
        scroll_page(driver)

        # Czekamy na za≈Çadowanie produkt√≥w
        print("‚è≥ Oczekiwanie na produkty...")
        wait.until(EC.presence_of_element_located((By.XPATH, "//li//article")))

        # ---------------------------------------------------------
        # EKSTRAKCJA DANYCH SESJI (Dostosowane do H&M)
        # ---------------------------------------------------------
        print(f"üìã Zbieranie danych do pliku: {OUTPUT_FILE}...")

        # 1. VIEWSTATE - H&M tego NIE u≈ºywa, ale zachowujemy format pliku
        view_state = "BRAK (H&M nie u≈ºywa technologii JSF ViewState)"

        # 2. COOKIES - H&M u≈ºywa wielu ciasteczek, pobieramy je wszystkie jako string
        cookies = driver.get_cookies()
        # Tworzymy string w formacie "name=value; name2=value2" (gotowy do nag≈Ç√≥wka Cookie)
        cookies_string = "; ".join([f"{c['name']}={c['value']}" for c in cookies])

        # Pobieramy User-Agent (wa≈ºne dla H&M bo majƒÖ zabezpieczenia przed botami)
        user_agent = driver.execute_script("return navigator.userAgent;")

        # 3. Znajd≈∫ produkty (artyku≈Çy)
        # Szukamy struktury: li -> article
        articles = driver.find_elements(By.XPATH, "//li//article")

        with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
            # Nag≈Ç√≥wek pliku w formacie z Twojego przyk≈Çadu
            f.write("# DANE SESJI (Dostosowane do H&M)\n")
            f.write(f"URL={TARGET_URL}\n")
            f.write(f"USER_AGENT={user_agent}\n")  # Dodatkowe, wa≈ºne dla H&M
            f.write(f"COOKIES_STRING={cookies_string}\n")  # Zamiast pojedynczego JSESSIONID
            f.write(f"VIEWSTATE={view_state}\n")
            f.write("-" * 100 + "\n")
            f.write("NR | NAZWA_PRODUKTU | LINK (HREF)\n")
            f.write("-" * 100 + "\n")

            count = 0
            processed_urls = set()

            for i, article in enumerate(articles):
                try:
                    # Krok A: Szukamy linku wewnƒÖtrz artyku≈Çu
                    # Szukamy tagu <a>, kt√≥ry ma href (dowolny, nie tylko productpage, ≈ºeby z≈Çapaƒá wszystko)
                    try:
                        link_element = article.find_element(By.TAG_NAME, "a")
                        href = link_element.get_attribute("href")
                    except:
                        continue  # Je≈õli nie ma linku, to nie produkt

                    # Filtracja duplikat√≥w i pustych link√≥w
                    if not href or href in processed_urls:
                        continue

                    # H&M czƒôsto ma linki typu 'javascript:void(0)' lub puste - pomijamy je
                    if "http" not in href:
                        continue

                    processed_urls.add(href)

                    # Krok B: Szukamy tytu≈Çu (tag <h2>) wewnƒÖtrz tego samego artyku≈Çu
                    try:
                        title_element = article.find_element(By.TAG_NAME, "h2")
                        product_name = title_element.text.strip().replace("\n", " ")
                    except:
                        product_name = "Brak nazwy"

                    # Zapis
                    f.write(f"{count} | {product_name} | {href}\n")
                    print(f"   ‚úÖ Znaleziono: {product_name}")
                    count += 1

                except StaleElementReferenceException:
                    # Element zniknƒÖ≈Ç przy przewijaniu
                    pass
                except Exception as e:
                    # print(f"B≈ÇƒÖd wiersza: {e}")
                    pass

        print("-" * 30)
        print(f"üéâ SUKCES! Zapisano {count} produkt√≥w do pliku '{OUTPUT_FILE}'.")
        print(f"üëâ Masz teraz listƒô URLi i ciasteczka potrzebne do ich pobrania.")

    except Exception as e:
        print(f"‚ùå WystƒÖpi≈Ç b≈ÇƒÖd: {e}")
        if driver:
            driver.save_screenshot("hm_error.png")

    finally:
        if driver:
            print("üëã Zamykanie przeglƒÖdarki...")
            driver.quit()


if __name__ == "__main__":
    run_scraper()